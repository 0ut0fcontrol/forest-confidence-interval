

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>calibration &mdash; forestci 0.3.0 documentation</title>
  

  
  
  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  

  
    <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="forestci 0.3.0 documentation" href="../index.html"/>
        <link rel="up" title="API Reference" href="index.html"/>
        <link rel="prev" title="forestci" href="forestci.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> forestci
          

          
          </a>

          
            
            
              <div class="version">
                0.3
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../installation_guide.html">Installation Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../auto_examples/index.html">Examples</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">API Reference</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="forestci.html"><code class="docutils literal"><span class="pre">forestci</span></code></a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#"><code class="docutils literal"><span class="pre">calibration</span></code></a><ul>
<li class="toctree-l3"><a class="reference internal" href="#calibrateeb">calibrateEB</a></li>
<li class="toctree-l3"><a class="reference internal" href="#fftconvolve">fftconvolve</a></li>
<li class="toctree-l3"><a class="reference internal" href="#gbayes">gbayes</a></li>
<li class="toctree-l3"><a class="reference internal" href="#gfit">gfit</a></li>
<li class="toctree-l3"><a class="reference internal" href="#minimize">minimize</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">forestci</a>
        
      </nav>


      
      <div class="wy-nav-content">
        <div class="rst-content">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">API Reference</a> &raquo;</li>
        
      <li><code class="docutils literal"><span class="pre">calibration</span></code></li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/reference/forestci.calibration.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-forestci.calibration">
<span id="calibration"></span><h1><code class="xref py py-mod docutils literal"><span class="pre">calibration</span></code><a class="headerlink" href="#module-forestci.calibration" title="Permalink to this headline">¶</a></h1>
<p>Calibration based on empirical Bayes estimation [Efron2014].</p>
<p>This calibration procedure can be useful when the number of trees in the
random forest is small.</p>
<table border="1" class="longtable docutils">
<colgroup>
<col width="10%" />
<col width="90%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><a class="reference internal" href="#forestci.calibration.calibrateEB" title="forestci.calibration.calibrateEB"><code class="xref py py-obj docutils literal"><span class="pre">calibrateEB</span></code></a>(variances,&nbsp;sigma2)</td>
<td>Calibrate noisy variance estimates with empirical Bayes.</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#forestci.calibration.fftconvolve" title="forestci.calibration.fftconvolve"><code class="xref py py-obj docutils literal"><span class="pre">fftconvolve</span></code></a>(in1,&nbsp;in2[,&nbsp;mode])</td>
<td>Convolve two N-dimensional arrays using FFT.</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#forestci.calibration.gbayes" title="forestci.calibration.gbayes"><code class="xref py py-obj docutils literal"><span class="pre">gbayes</span></code></a>(x0,&nbsp;g_est,&nbsp;sigma)</td>
<td>Estimate Bayes posterior with Gaussian noise [Efron2014].</td>
</tr>
<tr class="row-even"><td><a class="reference internal" href="#forestci.calibration.gfit" title="forestci.calibration.gfit"><code class="xref py py-obj docutils literal"><span class="pre">gfit</span></code></a>(X,&nbsp;sigma[,&nbsp;p,&nbsp;nbin,&nbsp;unif_fraction])</td>
<td>Fit empirical Bayes prior in the hierarchical model [Efron2014].</td>
</tr>
<tr class="row-odd"><td><a class="reference internal" href="#forestci.calibration.minimize" title="forestci.calibration.minimize"><code class="xref py py-obj docutils literal"><span class="pre">minimize</span></code></a>(fun,&nbsp;x0[,&nbsp;args,&nbsp;method,&nbsp;jac,&nbsp;hess,&nbsp;…])</td>
<td>Minimization of scalar function of one or more variables.</td>
</tr>
</tbody>
</table>
<div class="section" id="calibrateeb">
<h2>calibrateEB<a class="headerlink" href="#calibrateeb" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="forestci.calibration.calibrateEB">
<code class="descclassname">forestci.calibration.</code><code class="descname">calibrateEB</code><span class="sig-paren">(</span><em>variances</em>, <em>sigma2</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/forestci/calibration.html#calibrateEB"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#forestci.calibration.calibrateEB" title="Permalink to this definition">¶</a></dt>
<dd><p>Calibrate noisy variance estimates with empirical Bayes.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>vars: ndarray</strong></p>
<blockquote>
<div><p>List of variance estimates.</p>
</div></blockquote>
<p><strong>sigma2: int</strong></p>
<blockquote>
<div><p>Estimate of the Monte Carlo noise in vars.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">An array of the calibrated variance estimates</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="fftconvolve">
<h2>fftconvolve<a class="headerlink" href="#fftconvolve" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="forestci.calibration.fftconvolve">
<code class="descclassname">forestci.calibration.</code><code class="descname">fftconvolve</code><span class="sig-paren">(</span><em>in1</em>, <em>in2</em>, <em>mode='full'</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/scipy/signal/signaltools.html#fftconvolve"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#forestci.calibration.fftconvolve" title="Permalink to this definition">¶</a></dt>
<dd><p>Convolve two N-dimensional arrays using FFT.</p>
<p>Convolve <cite>in1</cite> and <cite>in2</cite> using the fast Fourier transform method, with
the output size determined by the <cite>mode</cite> argument.</p>
<p>This is generally much faster than <cite>convolve</cite> for large arrays (n &gt; ~500),
but can be slower when only a few output values are needed, and can only
output float arrays (int or object array inputs will be cast to float).</p>
<p>As of v0.19, <cite>convolve</cite> automatically chooses this method or the direct
method based on an estimation of which is faster.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>in1</strong> : array_like</p>
<blockquote>
<div><p>First input.</p>
</div></blockquote>
<p><strong>in2</strong> : array_like</p>
<blockquote>
<div><p>Second input. Should have the same number of dimensions as <cite>in1</cite>.
If operating in ‘valid’ mode, either <cite>in1</cite> or <cite>in2</cite> must be
at least as large as the other in every dimension.</p>
</div></blockquote>
<p><strong>mode</strong> : str {‘full’, ‘valid’, ‘same’}, optional</p>
<blockquote>
<div><p>A string indicating the size of the output:</p>
<dl class="docutils">
<dt><code class="docutils literal"><span class="pre">full</span></code></dt>
<dd><p class="first last">The output is the full discrete linear convolution
of the inputs. (Default)</p>
</dd>
<dt><code class="docutils literal"><span class="pre">valid</span></code></dt>
<dd><p class="first last">The output consists only of those elements that do not
rely on the zero-padding.</p>
</dd>
<dt><code class="docutils literal"><span class="pre">same</span></code></dt>
<dd><p class="first last">The output is the same size as <cite>in1</cite>, centered
with respect to the ‘full’ output.</p>
</dd>
</dl>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>out</strong> : array</p>
<blockquote class="last">
<div><p>An N-dimensional array containing a subset of the discrete linear
convolution of <cite>in1</cite> with <cite>in2</cite>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<p>Autocorrelation of white noise is an impulse.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">scipy</span> <span class="k">import</span> <span class="n">signal</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sig</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">autocorr</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">fftconvolve</span><span class="p">(</span><span class="n">sig</span><span class="p">,</span> <span class="n">sig</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;full&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax_orig</span><span class="p">,</span> <span class="n">ax_mag</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax_orig</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sig</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax_orig</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;White noise&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax_mag</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="nb">len</span><span class="p">(</span><span class="n">sig</span><span class="p">)</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">sig</span><span class="p">)),</span> <span class="n">autocorr</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax_mag</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Autocorrelation&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
<p>Gaussian blur implemented using FFT convolution.  Notice the dark borders
around the image, due to the zero-padding beyond its boundaries.
The <cite>convolve2d</cite> function allows for other types of image boundaries,
but is far slower.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">scipy</span> <span class="k">import</span> <span class="n">misc</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">face</span> <span class="o">=</span> <span class="n">misc</span><span class="o">.</span><span class="n">face</span><span class="p">(</span><span class="n">gray</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kernel</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">outer</span><span class="p">(</span><span class="n">signal</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="mi">70</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">signal</span><span class="o">.</span><span class="n">gaussian</span><span class="p">(</span><span class="mi">70</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">blurred</span> <span class="o">=</span> <span class="n">signal</span><span class="o">.</span><span class="n">fftconvolve</span><span class="p">(</span><span class="n">face</span><span class="p">,</span> <span class="n">kernel</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;same&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax_orig</span><span class="p">,</span> <span class="n">ax_kernel</span><span class="p">,</span> <span class="n">ax_blurred</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span>
<span class="gp">... </span>                                                     <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">15</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax_orig</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">face</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax_orig</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Original&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax_orig</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax_kernel</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">kernel</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax_kernel</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Gaussian kernel&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax_kernel</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax_blurred</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">blurred</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax_blurred</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">&#39;Blurred&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ax_blurred</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

</div>
<div class="section" id="gbayes">
<h2>gbayes<a class="headerlink" href="#gbayes" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="forestci.calibration.gbayes">
<code class="descclassname">forestci.calibration.</code><code class="descname">gbayes</code><span class="sig-paren">(</span><em>x0</em>, <em>g_est</em>, <em>sigma</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/forestci/calibration.html#gbayes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#forestci.calibration.gbayes" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimate Bayes posterior with Gaussian noise [Efron2014].</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>x0: ndarray</strong></p>
<blockquote>
<div><p>an observation</p>
</div></blockquote>
<p><strong>g_est: float</strong></p>
<blockquote>
<div><p>a prior density, as returned by gfit</p>
</div></blockquote>
<p><strong>sigma: int</strong></p>
<blockquote>
<div><p>noise estimate</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">An array of the posterior estimate E[mu | x0]</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="gfit">
<h2>gfit<a class="headerlink" href="#gfit" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="forestci.calibration.gfit">
<code class="descclassname">forestci.calibration.</code><code class="descname">gfit</code><span class="sig-paren">(</span><em>X</em>, <em>sigma</em>, <em>p=5</em>, <em>nbin=200</em>, <em>unif_fraction=0.1</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/forestci/calibration.html#gfit"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#forestci.calibration.gfit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit empirical Bayes prior in the hierarchical model [Efron2014].</p>
<div class="math">
<p><img src="../_images/math/e9a078cd65dac4463d85be1cc08918939e2b4ad7.png" alt="mu ~ G, X ~ N(mu, sigma^2)"/></p>
</div><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X: ndarray</strong></p>
<blockquote>
<div><p>A 1D array of observations.</p>
</div></blockquote>
<p><strong>sigma: float</strong></p>
<blockquote>
<div><p>Noise estimate on X.</p>
</div></blockquote>
<p><strong>p: int</strong></p>
<blockquote>
<div><p>Number of parameters used to fit G. Default: 5</p>
</div></blockquote>
<p><strong>nbin: int</strong></p>
<blockquote>
<div><p>Number of bins used for discrete approximation.
Default: 200</p>
</div></blockquote>
<p><strong>unif_fraction: float</strong></p>
<blockquote>
<div><p>Fraction of G modeled as “slab”. Default: 0.1</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">An array of the posterior density estimate g.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</div>
<div class="section" id="minimize">
<h2>minimize<a class="headerlink" href="#minimize" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="forestci.calibration.minimize">
<code class="descclassname">forestci.calibration.</code><code class="descname">minimize</code><span class="sig-paren">(</span><em>fun</em>, <em>x0</em>, <em>args=()</em>, <em>method=None</em>, <em>jac=None</em>, <em>hess=None</em>, <em>hessp=None</em>, <em>bounds=None</em>, <em>constraints=()</em>, <em>tol=None</em>, <em>callback=None</em>, <em>options=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/scipy/optimize/_minimize.html#minimize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#forestci.calibration.minimize" title="Permalink to this definition">¶</a></dt>
<dd><p>Minimization of scalar function of one or more variables.</p>
<p>In general, the optimization problems are of the form:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">minimize</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="n">subject</span> <span class="n">to</span>

<span class="n">g_i</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span>  <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="o">...</span><span class="p">,</span><span class="n">m</span>
<span class="n">h_j</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>  <span class="n">j</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span><span class="o">...</span><span class="p">,</span><span class="n">p</span>
</pre></div>
</div>
<p>where x is a vector of one or more variables.
<code class="docutils literal"><span class="pre">g_i(x)</span></code> are the inequality constraints.
<code class="docutils literal"><span class="pre">h_j(x)</span></code> are the equality constrains.</p>
<p>Optionally, the lower and upper bounds for each element in x can also be
specified using the <cite>bounds</cite> argument.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>fun</strong> : callable</p>
<blockquote>
<div><p>The objective function to be minimized. Must be in the form
<code class="docutils literal"><span class="pre">f(x,</span> <span class="pre">*args)</span></code>. The optimizing argument, <code class="docutils literal"><span class="pre">x</span></code>, is a 1-D array
of points, and <code class="docutils literal"><span class="pre">args</span></code> is a tuple of any additional fixed parameters
needed to completely specify the function.</p>
</div></blockquote>
<p><strong>x0</strong> : ndarray</p>
<blockquote>
<div><p>Initial guess. <code class="docutils literal"><span class="pre">len(x0)</span></code> is the dimensionality of the minimization
problem.</p>
</div></blockquote>
<p><strong>args</strong> : tuple, optional</p>
<blockquote>
<div><p>Extra arguments passed to the objective function and its
derivatives (Jacobian, Hessian).</p>
</div></blockquote>
<p><strong>method</strong> : str or callable, optional</p>
<blockquote>
<div><p>Type of solver.  Should be one of</p>
<blockquote>
<div><ul class="simple">
<li>‘Nelder-Mead’ <span class="xref std std-ref">(see here)</span></li>
<li>‘Powell’      <span class="xref std std-ref">(see here)</span></li>
<li>‘CG’          <span class="xref std std-ref">(see here)</span></li>
<li>‘BFGS’        <span class="xref std std-ref">(see here)</span></li>
<li>‘Newton-CG’   <span class="xref std std-ref">(see here)</span></li>
<li>‘L-BFGS-B’    <span class="xref std std-ref">(see here)</span></li>
<li>‘TNC’         <span class="xref std std-ref">(see here)</span></li>
<li>‘COBYLA’      <span class="xref std std-ref">(see here)</span></li>
<li>‘SLSQP’       <span class="xref std std-ref">(see here)</span></li>
<li>‘dogleg’      <span class="xref std std-ref">(see here)</span></li>
<li>‘trust-ncg’   <span class="xref std std-ref">(see here)</span></li>
<li>‘trust-exact’ <span class="xref std std-ref">(see here)</span></li>
<li>‘trust-krylov’ <span class="xref std std-ref">(see here)</span></li>
<li>custom - a callable object (added in version 0.14.0),
see below for description.</li>
</ul>
</div></blockquote>
<p>If not given, chosen to be one of <code class="docutils literal"><span class="pre">BFGS</span></code>, <code class="docutils literal"><span class="pre">L-BFGS-B</span></code>, <code class="docutils literal"><span class="pre">SLSQP</span></code>,
depending if the problem has constraints or bounds.</p>
</div></blockquote>
<p><strong>jac</strong> : bool or callable, optional</p>
<blockquote>
<div><p>Jacobian (gradient) of objective function. Only for CG, BFGS,
Newton-CG, L-BFGS-B, TNC, SLSQP, dogleg, trust-ncg, trust-krylov,
trust-region-exact.
If <cite>jac</cite> is a Boolean and is True, <cite>fun</cite> is assumed to return the
gradient along with the objective function. If False, the
gradient will be estimated numerically.
<cite>jac</cite> can also be a callable returning the gradient of the
objective. In this case, it must accept the same arguments as <cite>fun</cite>.</p>
</div></blockquote>
<p><strong>hess, hessp</strong> : callable, optional</p>
<blockquote>
<div><p>Hessian (matrix of second-order derivatives) of objective function or
Hessian of objective function times an arbitrary vector p.  Only for
Newton-CG, dogleg, trust-ncg, trust-krylov, trust-region-exact.
Only one of <cite>hessp</cite> or <cite>hess</cite> needs to be given.  If <cite>hess</cite> is
provided, then <cite>hessp</cite> will be ignored.  If neither <cite>hess</cite> nor
<cite>hessp</cite> is provided, then the Hessian product will be approximated
using finite differences on <cite>jac</cite>. <cite>hessp</cite> must compute the Hessian
times an arbitrary vector.</p>
</div></blockquote>
<p><strong>bounds</strong> : sequence, optional</p>
<blockquote>
<div><p>Bounds for variables (only for L-BFGS-B, TNC and SLSQP).
<code class="docutils literal"><span class="pre">(min,</span> <span class="pre">max)</span></code> pairs for each element in <code class="docutils literal"><span class="pre">x</span></code>, defining
the bounds on that parameter. Use None for one of <code class="docutils literal"><span class="pre">min</span></code> or
<code class="docutils literal"><span class="pre">max</span></code> when there is no bound in that direction.</p>
</div></blockquote>
<p><strong>constraints</strong> : dict or sequence of dict, optional</p>
<blockquote>
<div><p>Constraints definition (only for COBYLA and SLSQP).
Each constraint is defined in a dictionary with fields:</p>
<blockquote>
<div><dl class="docutils">
<dt>type <span class="classifier-delimiter">:</span> <span class="classifier">str</span></dt>
<dd><p class="first last">Constraint type: ‘eq’ for equality, ‘ineq’ for inequality.</p>
</dd>
<dt>fun <span class="classifier-delimiter">:</span> <span class="classifier">callable</span></dt>
<dd><p class="first last">The function defining the constraint.</p>
</dd>
<dt>jac <span class="classifier-delimiter">:</span> <span class="classifier">callable, optional</span></dt>
<dd><p class="first last">The Jacobian of <cite>fun</cite> (only for SLSQP).</p>
</dd>
<dt>args <span class="classifier-delimiter">:</span> <span class="classifier">sequence, optional</span></dt>
<dd><p class="first last">Extra arguments to be passed to the function and Jacobian.</p>
</dd>
</dl>
</div></blockquote>
<p>Equality constraint means that the constraint function result is to
be zero whereas inequality means that it is to be non-negative.
Note that COBYLA only supports inequality constraints.</p>
</div></blockquote>
<p><strong>tol</strong> : float, optional</p>
<blockquote>
<div><p>Tolerance for termination. For detailed control, use solver-specific
options.</p>
</div></blockquote>
<p><strong>options</strong> : dict, optional</p>
<blockquote>
<div><p>A dictionary of solver options. All methods accept the following
generic options:</p>
<blockquote>
<div><dl class="docutils">
<dt>maxiter <span class="classifier-delimiter">:</span> <span class="classifier">int</span></dt>
<dd><p class="first last">Maximum number of iterations to perform.</p>
</dd>
<dt>disp <span class="classifier-delimiter">:</span> <span class="classifier">bool</span></dt>
<dd><p class="first last">Set to True to print convergence messages.</p>
</dd>
</dl>
</div></blockquote>
<p>For method-specific options, see <code class="xref py py-func docutils literal"><span class="pre">show_options()</span></code>.</p>
</div></blockquote>
<p><strong>callback</strong> : callable, optional</p>
<blockquote>
<div><p>Called after each iteration, as <code class="docutils literal"><span class="pre">callback(xk)</span></code>, where <code class="docutils literal"><span class="pre">xk</span></code> is the
current parameter vector.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>res</strong> : OptimizeResult</p>
<blockquote class="last">
<div><p>The optimization result represented as a <code class="docutils literal"><span class="pre">OptimizeResult</span></code> object.
Important attributes are: <code class="docutils literal"><span class="pre">x</span></code> the solution array, <code class="docutils literal"><span class="pre">success</span></code> a
Boolean flag indicating if the optimizer exited successfully and
<code class="docutils literal"><span class="pre">message</span></code> which describes the cause of the termination. See
<cite>OptimizeResult</cite> for a description of other attributes.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<div class="admonition seealso">
<p class="first admonition-title">See also</p>
<dl class="last docutils">
<dt><code class="xref py py-obj docutils literal"><span class="pre">minimize_scalar</span></code></dt>
<dd>Interface to minimization algorithms for scalar univariate functions</dd>
<dt><code class="xref py py-obj docutils literal"><span class="pre">show_options</span></code></dt>
<dd>Additional options accepted by the solvers</dd>
</dl>
</div>
<p class="rubric">Notes</p>
<p>This section describes the available solvers that can be selected by the
‘method’ parameter. The default method is <em>BFGS</em>.</p>
<p><strong>Unconstrained minimization</strong></p>
<p>Method <span class="xref std std-ref">Nelder-Mead</span> uses the
Simplex algorithm <a class="reference internal" href="#r3751" id="id6">[R3751]</a>, <a class="reference internal" href="#r3851" id="id7">[R3851]</a>. This algorithm is robust in many
applications. However, if numerical computation of derivative can be
trusted, other algorithms using the first and/or second derivatives
information might be preferred for their better performance in
general.</p>
<p>Method <span class="xref std std-ref">Powell</span> is a modification
of Powell’s method <a class="reference internal" href="#r3951" id="id8">[R3951]</a>, <a class="reference internal" href="#r4051" id="id9">[R4051]</a> which is a conjugate direction
method. It performs sequential one-dimensional minimizations along
each vector of the directions set (<cite>direc</cite> field in <cite>options</cite> and
<cite>info</cite>), which is updated at each iteration of the main
minimization loop. The function need not be differentiable, and no
derivatives are taken.</p>
<p>Method <span class="xref std std-ref">CG</span> uses a nonlinear conjugate
gradient algorithm by Polak and Ribiere, a variant of the
Fletcher-Reeves method described in <a class="reference internal" href="#r4151" id="id10">[R4151]</a> pp.  120-122. Only the
first derivatives are used.</p>
<p>Method <span class="xref std std-ref">BFGS</span> uses the quasi-Newton
method of Broyden, Fletcher, Goldfarb, and Shanno (BFGS) <a class="reference internal" href="#r4151" id="id11">[R4151]</a>
pp. 136. It uses the first derivatives only. BFGS has proven good
performance even for non-smooth optimizations. This method also
returns an approximation of the Hessian inverse, stored as
<cite>hess_inv</cite> in the OptimizeResult object.</p>
<p>Method <span class="xref std std-ref">Newton-CG</span> uses a
Newton-CG algorithm <a class="reference internal" href="#r4151" id="id12">[R4151]</a> pp. 168 (also known as the truncated
Newton method). It uses a CG method to the compute the search
direction. See also <em>TNC</em> method for a box-constrained
minimization with a similar algorithm. Suitable for large-scale
problems.</p>
<p>Method <span class="xref std std-ref">dogleg</span> uses the dog-leg
trust-region algorithm <a class="reference internal" href="#r4151" id="id13">[R4151]</a> for unconstrained minimization. This
algorithm requires the gradient and Hessian; furthermore the
Hessian is required to be positive definite.</p>
<p>Method <span class="xref std std-ref">trust-ncg</span> uses the
Newton conjugate gradient trust-region algorithm <a class="reference internal" href="#r4151" id="id14">[R4151]</a> for
unconstrained minimization. This algorithm requires the gradient
and either the Hessian or a function that computes the product of
the Hessian with a given vector. Suitable for large-scale problems.</p>
<p>Method <span class="xref std std-ref">trust-krylov</span> uses
the Newton GLTR trust-region algorithm <a class="reference internal" href="#r5051" id="id15">[R5051]</a>, <a class="reference internal" href="#r5151" id="id16">[R5151]</a> for unconstrained
minimization. This algorithm requires the gradient
and either the Hessian or a function that computes the product of
the Hessian with a given vector. Suitable for large-scale problems.
On indefinite problems it requires usually less iterations than the
<cite>trust-ncg</cite> method and is recommended for medium and large-scale problems.</p>
<p>Method <span class="xref std std-ref">trust-exact</span>
is a trust-region method for unconstrained minimization in which
quadratic subproblems are solved almost exactly <a class="reference internal" href="#r4951" id="id17">[R4951]</a>. This
algorithm requires the gradient and the Hessian (which is
<em>not</em> required to be positive definite). It is, in many
situations, the Newton method to converge in fewer iteraction
and the most recommended for small and medium-size problems.</p>
<p><strong>Constrained minimization</strong></p>
<p>Method <span class="xref std std-ref">L-BFGS-B</span> uses the L-BFGS-B
algorithm <a class="reference internal" href="#r4251" id="id18">[R4251]</a>, <a class="reference internal" href="#r4351" id="id19">[R4351]</a> for bound constrained minimization.</p>
<p>Method <span class="xref std std-ref">TNC</span> uses a truncated Newton
algorithm <a class="reference internal" href="#r4151" id="id20">[R4151]</a>, <a class="reference internal" href="#r4451" id="id21">[R4451]</a> to minimize a function with variables subject
to bounds. This algorithm uses gradient information; it is also
called Newton Conjugate-Gradient. It differs from the <em>Newton-CG</em>
method described above as it wraps a C implementation and allows
each variable to be given upper and lower bounds.</p>
<p>Method <span class="xref std std-ref">COBYLA</span> uses the
Constrained Optimization BY Linear Approximation (COBYLA) method
<a class="reference internal" href="#r4551" id="id22">[R4551]</a>, <a class="reference internal" href="#r4651" id="id23">[R4651]</a>, <a class="reference internal" href="#r4751" id="id24">[R4751]</a>. The algorithm is based on linear
approximations to the objective function and each constraint. The
method wraps a FORTRAN implementation of the algorithm. The
constraints functions ‘fun’ may return either a single number
or an array or list of numbers.</p>
<p>Method <span class="xref std std-ref">SLSQP</span> uses Sequential
Least SQuares Programming to minimize a function of several
variables with any combination of bounds, equality and inequality
constraints. The method wraps the SLSQP Optimization subroutine
originally implemented by Dieter Kraft <a class="reference internal" href="#r4851" id="id25">[R4851]</a>. Note that the
wrapper handles infinite values in bounds by converting them into
large floating values.</p>
<p><strong>Custom minimizers</strong></p>
<p>It may be useful to pass a custom minimization method, for example
when using a frontend to this method such as <cite>scipy.optimize.basinhopping</cite>
or a different library.  You can simply pass a callable as the <code class="docutils literal"><span class="pre">method</span></code>
parameter.</p>
<p>The callable is called as <code class="docutils literal"><span class="pre">method(fun,</span> <span class="pre">x0,</span> <span class="pre">args,</span> <span class="pre">**kwargs,</span> <span class="pre">**options)</span></code>
where <code class="docutils literal"><span class="pre">kwargs</span></code> corresponds to any other parameters passed to <cite>minimize</cite>
(such as <cite>callback</cite>, <cite>hess</cite>, etc.), except the <cite>options</cite> dict, which has
its contents also passed as <cite>method</cite> parameters pair by pair.  Also, if
<cite>jac</cite> has been passed as a bool type, <cite>jac</cite> and <cite>fun</cite> are mangled so that
<cite>fun</cite> returns just the function values and <cite>jac</cite> is converted to a function
returning the Jacobian.  The method shall return an <code class="docutils literal"><span class="pre">OptimizeResult</span></code>
object.</p>
<p>The provided <cite>method</cite> callable must be able to accept (and possibly ignore)
arbitrary parameters; the set of parameters accepted by <cite>minimize</cite> may
expand in future versions and then these parameters will be passed to
the method.  You can find an example in the scipy.optimize tutorial.</p>
<div class="versionadded">
<p><span class="versionmodified">New in version 0.11.0.</span></p>
</div>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r3751" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[R3751]</td><td><em>(<a class="fn-backref" href="#id6">1</a>, <a class="fn-backref" href="#id26">2</a>)</em> Nelder, J A, and R Mead. 1965. A Simplex Method for Function
Minimization. The Computer Journal 7: 308-13.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r3851" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[R3851]</td><td><em>(<a class="fn-backref" href="#id7">1</a>, <a class="fn-backref" href="#id27">2</a>)</em> Wright M H. 1996. Direct search methods: Once scorned, now
respectable, in Numerical Analysis 1995: Proceedings of the 1995
Dundee Biennial Conference in Numerical Analysis (Eds. D F
Griffiths and G A Watson). Addison Wesley Longman, Harlow, UK.
191-208.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r3951" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[R3951]</td><td><em>(<a class="fn-backref" href="#id8">1</a>, <a class="fn-backref" href="#id28">2</a>)</em> Powell, M J D. 1964. An efficient method for finding the minimum of
a function of several variables without calculating derivatives. The
Computer Journal 7: 155-162.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r4051" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[R4051]</td><td><em>(<a class="fn-backref" href="#id9">1</a>, <a class="fn-backref" href="#id29">2</a>)</em> Press W, S A Teukolsky, W T Vetterling and B P Flannery.
Numerical Recipes (any edition), Cambridge University Press.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r4151" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[R4151]</td><td><em>(<a class="fn-backref" href="#id10">1</a>, <a class="fn-backref" href="#id11">2</a>, <a class="fn-backref" href="#id12">3</a>, <a class="fn-backref" href="#id13">4</a>, <a class="fn-backref" href="#id14">5</a>, <a class="fn-backref" href="#id20">6</a>, <a class="fn-backref" href="#id30">7</a>, <a class="fn-backref" href="#id41">8</a>)</em> Nocedal, J, and S J Wright. 2006. Numerical Optimization.
Springer New York.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r4251" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[R4251]</td><td><em>(<a class="fn-backref" href="#id18">1</a>, <a class="fn-backref" href="#id31">2</a>)</em> Byrd, R H and P Lu and J. Nocedal. 1995. A Limited Memory
Algorithm for Bound Constrained Optimization. SIAM Journal on
Scientific and Statistical Computing 16 (5): 1190-1208.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r4351" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[R4351]</td><td><em>(<a class="fn-backref" href="#id19">1</a>, <a class="fn-backref" href="#id32">2</a>)</em> Zhu, C and R H Byrd and J Nocedal. 1997. L-BFGS-B: Algorithm
778: L-BFGS-B, FORTRAN routines for large scale bound constrained
optimization. ACM Transactions on Mathematical Software 23 (4):
550-560.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r4451" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[R4451]</td><td><em>(<a class="fn-backref" href="#id21">1</a>, <a class="fn-backref" href="#id33">2</a>)</em> Nash, S G. Newton-Type Minimization Via the Lanczos Method.
1984. SIAM Journal of Numerical Analysis 21: 770-778.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r4551" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[R4551]</td><td><em>(<a class="fn-backref" href="#id22">1</a>, <a class="fn-backref" href="#id34">2</a>)</em> Powell, M J D. A direct search optimization method that models
the objective and constraint functions by linear interpolation.
1994. Advances in Optimization and Numerical Analysis, eds. S. Gomez
and J-P Hennart, Kluwer Academic (Dordrecht), 51-67.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r4651" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[R4651]</td><td><em>(<a class="fn-backref" href="#id23">1</a>, <a class="fn-backref" href="#id35">2</a>)</em> Powell M J D. Direct search algorithms for optimization
calculations. 1998. Acta Numerica 7: 287-336.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r4751" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[R4751]</td><td><em>(<a class="fn-backref" href="#id24">1</a>, <a class="fn-backref" href="#id36">2</a>)</em> Powell M J D. A view of algorithms for optimization without
derivatives. 2007.Cambridge University Technical Report DAMTP
2007/NA03</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r4851" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[R4851]</td><td><em>(<a class="fn-backref" href="#id25">1</a>, <a class="fn-backref" href="#id37">2</a>)</em> Kraft, D. A software package for sequential quadratic
programming. 1988. Tech. Rep. DFVLR-FB 88-28, DLR German Aerospace
Center – Institute for Flight Mechanics, Koln, Germany.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r4951" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[R4951]</td><td><em>(<a class="fn-backref" href="#id17">1</a>, <a class="fn-backref" href="#id38">2</a>)</em> Conn, A. R., Gould, N. I., and Toint, P. L.
Trust region methods. 2000. Siam. pp. 169-200.</td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r5051" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[R5051]</td><td><em>(<a class="fn-backref" href="#id15">1</a>, <a class="fn-backref" href="#id39">2</a>)</em> F. Lenders, C. Kirches, A. Potschka: “trlib: A vector-free
implementation of the GLTR method for iterative solution of
the trust region problem”, <a class="reference external" href="https://arxiv.org/abs/1611.04718">https://arxiv.org/abs/1611.04718</a></td></tr>
</tbody>
</table>
<table class="docutils citation" frame="void" id="r5151" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[R5151]</td><td><em>(<a class="fn-backref" href="#id16">1</a>, <a class="fn-backref" href="#id40">2</a>)</em> N. Gould, S. Lucidi, M. Roma, P. Toint: “Solving the
Trust-Region Subproblem using the Lanczos Method”,
SIAM J. Optim., 9(2), 504–525, (1999).</td></tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<p>Let us consider the problem of minimizing the Rosenbrock function. This
function (and its respective derivatives) is implemented in <cite>rosen</cite>
(resp. <cite>rosen_der</cite>, <cite>rosen_hess</cite>) in the <cite>scipy.optimize</cite>.</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="k">import</span> <span class="n">minimize</span><span class="p">,</span> <span class="n">rosen</span><span class="p">,</span> <span class="n">rosen_der</span>
</pre></div>
</div>
<p>A simple application of the <em>Nelder-Mead</em> method is:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">x0</span> <span class="o">=</span> <span class="p">[</span><span class="mf">1.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mf">1.9</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">rosen</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;Nelder-Mead&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">x</span>
<span class="go">array([ 1.,  1.,  1.,  1.,  1.])</span>
</pre></div>
</div>
<p>Now using the <em>BFGS</em> algorithm, using the first derivative and a few
options:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">rosen</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;BFGS&#39;</span><span class="p">,</span> <span class="n">jac</span><span class="o">=</span><span class="n">rosen_der</span><span class="p">,</span>
<span class="gp">... </span>               <span class="n">options</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;gtol&#39;</span><span class="p">:</span> <span class="mf">1e-6</span><span class="p">,</span> <span class="s1">&#39;disp&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span>
<span class="go">Optimization terminated successfully.</span>
<span class="go">         Current function value: 0.000000</span>
<span class="go">         Iterations: 26</span>
<span class="go">         Function evaluations: 31</span>
<span class="go">         Gradient evaluations: 31</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">x</span>
<span class="go">array([ 1.,  1.,  1.,  1.,  1.])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">res</span><span class="o">.</span><span class="n">message</span><span class="p">)</span>
<span class="go">Optimization terminated successfully.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">res</span><span class="o">.</span><span class="n">hess_inv</span>
<span class="go">array([[ 0.00749589,  0.01255155,  0.02396251,  0.04750988,  0.09495377],  # may vary</span>
<span class="go">       [ 0.01255155,  0.02510441,  0.04794055,  0.09502834,  0.18996269],</span>
<span class="go">       [ 0.02396251,  0.04794055,  0.09631614,  0.19092151,  0.38165151],</span>
<span class="go">       [ 0.04750988,  0.09502834,  0.19092151,  0.38341252,  0.7664427 ],</span>
<span class="go">       [ 0.09495377,  0.18996269,  0.38165151,  0.7664427,   1.53713523]])</span>
</pre></div>
</div>
<p>Next, consider a minimization problem with several constraints (namely
Example 16.4 from <a class="reference internal" href="#r4151" id="id41">[R4151]</a>). The objective function is:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">fun</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span> <span class="o">+</span> <span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="mf">2.5</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span>
</pre></div>
</div>
<p>There are three constraints defined as:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">cons</span> <span class="o">=</span> <span class="p">({</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;ineq&#39;</span><span class="p">,</span> <span class="s1">&#39;fun&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span>  <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">2</span><span class="p">},</span>
<span class="gp">... </span>        <span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;ineq&#39;</span><span class="p">,</span> <span class="s1">&#39;fun&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">6</span><span class="p">},</span>
<span class="gp">... </span>        <span class="p">{</span><span class="s1">&#39;type&#39;</span><span class="p">:</span> <span class="s1">&#39;ineq&#39;</span><span class="p">,</span> <span class="s1">&#39;fun&#39;</span><span class="p">:</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="mi">2</span><span class="p">})</span>
</pre></div>
</div>
<p>And variables must be positive, hence the following bounds:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">bnds</span> <span class="o">=</span> <span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">))</span>
</pre></div>
</div>
<p>The optimization problem is solved using the SLSQP method as:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">res</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">fun</span><span class="p">,</span> <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">method</span><span class="o">=</span><span class="s1">&#39;SLSQP&#39;</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="n">bnds</span><span class="p">,</span>
<span class="gp">... </span>               <span class="n">constraints</span><span class="o">=</span><span class="n">cons</span><span class="p">)</span>
</pre></div>
</div>
<p>It should converge to the theoretical solution (1.4 ,1.7).</p>
</dd></dl>

</div>
</div>


           </div>
           <div class="articleComments">
            
           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="forestci.html" class="btn btn-neutral" title="forestci" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2016, Kivan Polimis, Ariel Rokem, Bryna Hazelton, The University of Washington eScience Institute.

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'0.3.0',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>